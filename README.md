<h1 align="left">Reconnaissance d'Expressions Faciales avec RAF-DB (SVM, CNN, TL)</h1>

###


<h3 align="left">ğŸ¯ Contexte du Projet</h3>

###

<p align="left">Le RAF-DB (Real-World Affective Face Database) est un dataset regroupant des images de visages humains Ã©tiquetÃ©es selon sept Ã©motions :</p>

###


<p align="center">â­‘ Bonheur (Happy)<br>â­‘ ColÃ¨re (Angry)<br>â­‘ Tristesse (Sad)<br>â­‘ Peur (Fear)<br>â­‘ DÃ©goÃ»t (Disgust)<br>â­‘ Surprise (Surprise)<br>â­‘ Neutre (Neutral)</p>

###

<p align="left">Ces Ã©motions sont essentielles dans des domaines comme l'interaction homme-machine, la psychologie et l'informatique affective. La reconnaissance des Ã©motions faciales (FER - Facial Emotion Recognition) trouve des applications pratiques dans divers secteurs :<br><br>âœ Service client : analyse en temps rÃ©el de la satisfaction des clients.<br>âœ SÃ©curitÃ© : dÃ©tection d'individus suspects ou menaÃ§ants.<br>âœ SantÃ© : suivi des Ã©tats Ã©motionnels des patients, notamment ceux ayant des troubles psychologiques.<br>âœ Interaction humain-robot : amÃ©lioration de la communication homme-robot.<br><br>Un dÃ©fi majeur de ce projet est le dÃ©sÃ©quilibre des classes dans le dataset, certaines Ã©motions Ã©tant plus reprÃ©sentÃ©es que d'autres, ce qui peut influencer les performances des modÃ¨les.</p>

###

<p align="left"></p>

###

<br clear="both">

<h3 align="left">ğŸ“ Objectifs du Projet</h3>

###

<br clear="both">

<p align="left">L'objectif principal est de classifier les expressions faciales issues du dataset RAF-DB en sept catÃ©gories d'Ã©motions. Les Ã©tapes incluent :<br><br>âœ¨ PrÃ©traitement des donnÃ©es : Chargement, redimensionnement et normalisation des images tout en gÃ©rant le dÃ©sÃ©quilibre des classes.<br><br>âœ¨ Construction et comparaison de modÃ¨les :<br> ğŸ‡´ SVM (Support Vector Machine) : ModÃ¨le traditionnel de machine learning utilisÃ© comme rÃ©fÃ©rence.<br> ğŸ‡´ CNN (Convolutional Neural Network) : RÃ©seau profond capable d'apprendre automatiquement les caractÃ©ristiques des images.<br> ğŸ‡´ Apprentissage par Transfert (DenseNet) : ModÃ¨les prÃ©-entraÃ®nÃ©s sur de grands datasets (comme ImageNet), adaptÃ©s Ã  la tÃ¢che de reconnaissance des Ã©motions.</p>

###

<div align="center">
  <img height="250" src="https://github.com/ibtihel-dhaouadi/Reconnaissance-d-Expressions-Faciales-avec-SVM-CNN-Transfert-Learning-/blob/main/result%20models.png"  />
</div>

###

<h3 align="left">âš™ï¸ FonctionnalitÃ©s</h3>

###

<h4 align="left">1 - Notebook principal : <a href="https://www.kaggle.com/code/dhaouadiibtihel98/raf-db-facial-expression-recognition-svm-cnn-tl">[Lien vers le notebook]</a>  <br>âœ PrÃ©paration des donnÃ©es, entraÃ®nement des modÃ¨les et comparaison des performances.<br><br>2 - Application interactive avec test en temps rÃ©el :<br>âœ Fichier TestEmotionDetector.py permettant  de tester le modÃ¨le CNN en temps rÃ©el grÃ¢ce Ã  une webcam. Lâ€™application dÃ©tecte les visages, prÃ©dit lâ€™Ã©motion correspondante et lâ€™affiche Ã  lâ€™Ã©cran. </h4>

###

<div align="center">
  <img height="400" src="https://github.com/ibtihel-dhaouadi/Reconnaissance-d-Expressions-Faciales-avec-SVM-CNN-Transfert-Learning-/blob/main/result%20test.png"  />
</div>

###

<br clear="both">

<h3 align="left">ğŸ‘¨ğŸ»â€ğŸ’» Technologies utilisÃ©es :</h3>

###

<div align="right">
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vscode/vscode-original.svg" height="40" alt="vscode logo"  />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" height="40" alt="python logo"  />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/kaggle/kaggle-original.svg" height="40" alt="kaggle logo"  />
</div>

###

<p align="left">âœ”ï¸  Langage principal: Langage principal pour la manipulation et l'analyse des donnÃ©es.<br><br>âœ”ï¸ BibliothÃ¨ques principales :<br>- TensorFlow/Keras : DÃ©veloppement des modÃ¨les CNN et transfert d'apprentissage.<br>- OpenCV : DÃ©tection des visages et traitement des flux vidÃ©o.<br>- Tkinter : CrÃ©ation d'une interface utilisateur pour tester le modÃ¨le en temps rÃ©el.<br><br>âœ”ï¸ Outils et environnements :<br>âœ kaggle Notebook : UtilisÃ© pour lâ€™entraÃ®nement des modÃ¨les sur GPU, accÃ©lÃ©rant considÃ©rablement les calculs.<br>âœ Visual Studio Code : Environnement de dÃ©veloppement intÃ©grÃ© (IDE) pour le dÃ©veloppement et les tests.</p>

###

<br clear="both">

<h3 align="left">ğŸ“Œ RÃ©sultats:</h3>

###

<p align="left">Le projet a permis de comparer les performances de trois approches diffÃ©rentes (SVM, CNN et transfert d'apprentissage). L'application interactive montre les prÃ©dictions en temps rÃ©el, facilitant une meilleure comprÃ©hension et utilisation des modÃ¨les dÃ©veloppÃ©s.</p>

###

<br clear="both">

<h3 align="left">ğŸ”š Conclusion :</h3>

###

<p align="left">Ce projet dÃ©montre l'efficacitÃ© des approches basÃ©es sur l'apprentissage profond, en particulier avec l'apprentissage par transfert, pour rÃ©soudre les problÃ¨mes complexes de reconnaissance d'expressions faciales. L'application interactive constitue un outil utile pour visualiser les rÃ©sultats en action.</p>

###

<p align="center">Le code, les rÃ©sultats dÃ©taillÃ©s et le fichier interactif sont disponibles dans les rÃ©pertoires suivants :<br><br>Notebook d'analyse : <a href="https://www.kaggle.com/code/dhaouadiibtihel98/raf-db-facial-expression-recognition-svm-cnn-tl">[Lien vers le notebook]</a> <br>Fichier interactif : testEmotionDetector.py</p>

###

<p align="center">TÃ©lÃ©chargez Ã©galement le fichier du meilleur modÃ¨le (best_model.h5) depuis l'output du notebook.</p>

###

<h6 align="center">ğŸ”— Nâ€™hÃ©sitez pas Ã  consulter les fichiers attachÃ© Ã  ce dÃ©pÃ´t pour plus de dÃ©tails. Vos commentaires et suggestions sont les bienvenus !</h6>

###
